# jps-scrape Full Documentation

# Automatic Web Scraping Scheduler

This Python script serves as an automatic scheduler for web scraping tasks. It determines the current day of the week and executes a web scraping script only on Wednesdays and Saturdays.

## How it works

The script utilizes the `datetime` module to retrieve the current day of the week (0 for Monday, 1 for Tuesday, ..., 6 for Sunday). If the current day is either Wednesday (2) or Saturday (5), it invokes the specified web scraping script (`scrape.py`) using the `subprocess` module.

## Usage

1. Ensure that Python is installed on your system.
2. Customize the web scraping script to be executed (`scrape.py`).
3. Run the scheduler script:

   ```bash
   python scheduler.py
   ```

4. The script will check the current day, and if it's Wednesday or Saturday, it will execute the web scraping script.

## Dependencies

- Python 3.x

## Notes

- Adjust the `scrape.py` script to match your specific web scraping requirements.
- This scheduler is set to execute on Wednesdays and Saturdays. Modify the `dia_semana_actual` check to suit your preferred schedule.

# Web Scraping Script

This Python script performs web scraping on a specified URL, saving the HTML content to a file with the current date as part of the name. It is designed to be used in conjunction with a web scraping scheduler.

## How it works

1. The script uses the Selenium library to open a headless browser, navigate to the specified URL (`https://www.jps.go.cr/productos/chances`), and wait for the page to load.
2. It retrieves the current year and constructs a file name with the format `YYYY/chances_DAY_dd_MONTH.html`.
3. The HTML content is extracted after the JavaScript has executed.
4. The browser is closed, and the HTML content is saved to a file with the constructed name.

## Usage

1. Ensure that Python is installed on your system.
2. Install the necessary libraries:

pip install selenium

3. Download and install the appropriate WebDriver for Chrome.
4. Customize the URL and other settings as needed.
5. Run the script:

python scrape.py

6. The script will save the HTML content to a file with the current date as part of the name.

## Dependencies

- Python 3.x
- Selenium library

# Data Extraction and Sorting Script

This Python script is responsible for extracting relevant information from an HTML file generated by the web scraping script (`scrape.py`). It uses BeautifulSoup to parse the HTML and extracts specific information based on the HTML structure. The extracted data is then saved to a file named `lucky.txt`, and a subprocess is called to run another script (`sort.py`) that sorts and counts the occurrences of the extracted data.

## How it works

1. The script reads the HTML content from the file generated by `scrape.py` with a file name formatted as `2024/chances_DAY_dd_MONTH.html`.
2. It uses BeautifulSoup to find all `<span>` tags with specific classes ('numero' or 'serie' with '\_0' in the class name) and extracts the text content.
3. The extracted text is printed to the console and appended to the file `lucky.txt`.
4. A subprocess is called to run the sorting script (`sort.py`), passing the name of the HTML file as an argument.

## Usage

1. Ensure that Python is installed on your system.
2. Install the necessary libraries:

pip install beautifulsoup4

3. Run the script:

python beautifulsoup.py

4. The script will print the extracted text to the console and append it to the `lucky.txt` file.

5. Additionally, it will call the sorting script (`sort.py`) with the name of the HTML file as an argument.

## Dependencies

- Python 3.x
- BeautifulSoup library

# Sorting and Counting Script

This Python script takes the data from the `lucky.txt` file, which contains extracted information, and counts the frequency of each number. It then sorts the numbers based on their frequency in descending order and saves the sorted data to a file named `lucky_SORTED.txt`.

## How it works

1. The script reads the content of the `lucky.txt` file.
2. It uses the Counter class to count the frequency of each number.
3. The numbers are sorted based on their frequency in descending order.
4. The sorted numbers are printed to the console.
5. The sorted numbers are saved to the `lucky_SORTED.txt` file.

## Usage

1. Ensure that Python is installed on your system.
2. Run the script:

   ```bash
   python sort.py
   ```

Certainly! Here is the content in plain text format:

markdown
Copy code

# Sorting and Counting Script

This Python script takes the data from the `lucky.txt` file, which contains extracted information, and counts the frequency of each number. It then sorts the numbers based on their frequency in descending order and saves the sorted data to a file named `lucky_SORTED.txt`.

## How it works

1. The script reads the content of the `lucky.txt` file.
2. It uses the Counter class to count the frequency of each number.
3. The numbers are sorted based on their frequency in descending order.
4. The sorted numbers are printed to the console.
5. The sorted numbers are saved to the `lucky_SORTED.txt` file.

## Usage

1. Ensure that Python is installed on your system.
2. Run the script:

   ```bash
   python sort.py
   The script will print the sorted numbers to the console and save them to the lucky_SORTED.txt file.
   Dependencies
   Python 3.x
   Counter class from the collections module
   ```

